{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a36600248-eng/toy/blob/main/kohya_ss_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NrgcDwZxgDOe",
        "outputId": "0ec7a510-cd17-45a0-fcee-bfb242cc6f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,302 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:9 https://cli.github.com/packages stable/main amd64 Packages [354 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,870 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,600 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,968 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,623 kB]\n",
            "Hit:20 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Get:23 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:24 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [45.0 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,637 kB]\n",
            "Fetched 38.6 MB in 3s (12.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 95 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Fetched 1,513 kB in 1s (2,294 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Error: Command '['/content/kohya_venv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "/bin/bash: line 1: /content/kohya_venv/bin/pip: No such file or directory\n",
            "/content\n",
            "Cloning into 'kohya_ss'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: '/content/kohya_ss'\n",
            "/content\n",
            "No requirements file found!\n",
            "total 2082672\n",
            "drwxr-xr-x 1 root root       4096 Jan 19 01:19 .\n",
            "drwxr-xr-x 1 root root       4096 Jan 19 01:14 ..\n",
            "drwxr-xr-x 4 root root       4096 Dec  9 14:41 .config\n",
            "drwx------ 5 root root       4096 Jan 19 01:19 drive\n",
            "drwxr-xr-x 5 root root       4096 Jan 19 01:19 kohya_venv\n",
            "-rw-r--r-- 1 root root 2132626090 Jan 19 01:18 model.safetensors\n",
            "drwxr-xr-x 1 root root       4096 Dec  9 14:42 sample_data\n",
            "/content/kohya_venv/bin/python: can't open file '/content/kohya_gui.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# ====== å®˜æ–¹ kohya-ss GUIï¼ˆç¨³å®šç‰ˆï¼‰Colab ä¸€é”®è„šæœ¬ ======\n",
        "%cd /content\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1) ç³»ç»Ÿä¾èµ–\n",
        "!apt-get -y update\n",
        "!apt-get -y install git aria2\n",
        "\n",
        "# 2) å»º venvï¼šå…³é”®ç‚¹æ˜¯ --system-site-packages\n",
        "#    è¿™æ · venv é‡Œèƒ½ç›´æ¥ç”¨ Colab é¢„è£…çš„ torch/cudaï¼ˆé¿å…ä½ ä¹‹å‰é‚£ç§ python è·¯å¾„é”™ä¹±ï¼‰\n",
        "!python3 -m venv --system-site-packages /content/kohya_venv\n",
        "KPY=\"/content/kohya_venv/bin/python\"\n",
        "KPIP=\"/content/kohya_venv/bin/pip\"\n",
        "\n",
        "# 3) å‡çº§ pip åŸºç¡€å·¥å…·\n",
        "!{KPIP} -q install -U pip setuptools wheel\n",
        "\n",
        "# 4) æ‹‰å®˜æ–¹ kohya_ssï¼ˆGUI ç‰ˆï¼‰\n",
        "%cd /content\n",
        "!rm -rf /content/kohya_ss\n",
        "!git clone https://github.com/kohya-ss/kohya_ss.git\n",
        "%cd /content/kohya_ss\n",
        "\n",
        "# 5) å®‰è£…ä¾èµ–ï¼šè¿‡æ»¤æ‰ bitsandbytesï¼ˆä½ ç°åœ¨çš„ CUDA 12.6 ä¼šæŠŠ bnb æç‚¸ï¼‰\n",
        "#    ä¾èµ–æ–‡ä»¶åå¯èƒ½æ˜¯ requirements.txt / requirements_gui.txt / requirements_linux.txt ç­‰\n",
        "#    è¿™é‡Œç”¨â€œå­˜åœ¨å°±è£…â€çš„æ–¹å¼ï¼Œå°½é‡å…¼å®¹ä¸åŒç‰ˆæœ¬ä»“åº“ç»“æ„\n",
        "!bash -lc 'set -e; \\\n",
        "  REQ=\"\"; \\\n",
        "  if [ -f requirements.txt ]; then REQ=\"requirements.txt\"; fi; \\\n",
        "  if [ -f requirements_gui.txt ]; then REQ=\"requirements_gui.txt\"; fi; \\\n",
        "  if [ -f requirements_linux.txt ]; then REQ=\"requirements_linux.txt\"; fi; \\\n",
        "  if [ -z \"$REQ\" ]; then echo \"No requirements file found!\"; ls -la; exit 1; fi; \\\n",
        "  echo \"Using requirements file: $REQ\"; \\\n",
        "  sed \"/bitsandbytes/d\" \"$REQ\" > /content/req_nobnb.txt; \\\n",
        "  /content/kohya_venv/bin/pip -q install -r /content/req_nobnb.txt; \\\n",
        "  /content/kohya_venv/bin/pip -q install -U voluptuous'\n",
        "\n",
        "# 6) å¯åŠ¨ GUIï¼ˆç½‘é¡µç•Œé¢ï¼‰\n",
        "#    çœ‹åˆ° â€œRunning on public URL:â€ é‚£è¡Œå°±æ˜¯ä½ çš„è®¿é—®é“¾æ¥\n",
        "!{KPY} kohya_gui.py --share --headless\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3B4_orangemixs.safetensors\" -O /content/model.safetensors"
      ],
      "metadata": {
        "id": "Vw33LmHQ1Gt8",
        "outputId": "5c515173-82c0-4c9b-85d1-0e5f953d1573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-19 01:18:02--  https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3B4_orangemixs.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.85, 108.138.246.67, 108.138.246.79, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/638cac3a61eb5101751a23c4/21501367dc185b5e4a7f08084d5c8b8ef456dbb130c1e61aeb3e2eb9d1347967?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27AOM3B4_orangemixs.safetensors%3B+filename%3D%22AOM3B4_orangemixs.safetensors%22%3B&Expires=1768789082&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY4Nzg5MDgyfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjM4Y2FjM2E2MWViNTEwMTc1MWEyM2M0LzIxNTAxMzY3ZGMxODViNWU0YTdmMDgwODRkNWM4YjhlZjQ1NmRiYjEzMGMxZTYxYWViM2UyZWI5ZDEzNDc5NjdcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=W4immfXQcB4iILbhypLd7BsJg5gHcHRKk81PZRppjbVznBsBRbaxI9g7mLt6G4Jt9%7ECAOt0QV8VEdoVtxm2IiISRadL1zfnK8W394pjwAJx%7EYaAuQVkysIK92Dd-LJK4LUgLVkSOqJ%7EVAPHm-A69OttArsFSxzaLisWp9GKrQ9FJJHmfOW3QTuOyQozr7q11QO2%7E3q%7Ecv3iPkvd3GCNx5-EX3zRduBQkKX7lYW24WvGPY88SD3%7EgSEEtughvzHLYRwYbpIqSuvNebUAJAaopnOIKNPiKEqzpP2MF9EUnapyTH5jjVA9-O48Fu%7E2wo4nBjGMFD2MPaACfa0%7ED-4vqJw__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-19 01:18:02--  https://us.gcp.cdn.hf.co/xet-bridge-us/638cac3a61eb5101751a23c4/21501367dc185b5e4a7f08084d5c8b8ef456dbb130c1e61aeb3e2eb9d1347967?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27AOM3B4_orangemixs.safetensors%3B+filename%3D%22AOM3B4_orangemixs.safetensors%22%3B&Expires=1768789082&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY4Nzg5MDgyfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjM4Y2FjM2E2MWViNTEwMTc1MWEyM2M0LzIxNTAxMzY3ZGMxODViNWU0YTdmMDgwODRkNWM4YjhlZjQ1NmRiYjEzMGMxZTYxYWViM2UyZWI5ZDEzNDc5NjdcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=W4immfXQcB4iILbhypLd7BsJg5gHcHRKk81PZRppjbVznBsBRbaxI9g7mLt6G4Jt9%7ECAOt0QV8VEdoVtxm2IiISRadL1zfnK8W394pjwAJx%7EYaAuQVkysIK92Dd-LJK4LUgLVkSOqJ%7EVAPHm-A69OttArsFSxzaLisWp9GKrQ9FJJHmfOW3QTuOyQozr7q11QO2%7E3q%7Ecv3iPkvd3GCNx5-EX3zRduBQkKX7lYW24WvGPY88SD3%7EgSEEtughvzHLYRwYbpIqSuvNebUAJAaopnOIKNPiKEqzpP2MF9EUnapyTH5jjVA9-O48Fu%7E2wo4nBjGMFD2MPaACfa0%7ED-4vqJw__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2132626090 (2.0G) [application/octet-stream]\n",
            "Saving to: â€˜/content/model.safetensorsâ€™\n",
            "\n",
            "/content/model.safe 100%[===================>]   1.99G  79.2MB/s    in 30s     \n",
            "\n",
            "2026-01-19 01:18:32 (68.5 MB/s) - â€˜/content/model.safetensorsâ€™ saved [2132626090/2132626090]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ä¸€é”®é¢„å¤„ç†ï¼šè‡ªåŠ¨é‡å‘½å + æ™ºèƒ½æ‰“æ ‡ (GLM-4.6v)\n",
        "# @markdown ### 1. æ ¸å¿ƒé…ç½®\n",
        "import os\n",
        "import glob\n",
        "import base64\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# [å¿…é¡»å¡«] ä½ çš„æ™ºè°±AI API Key\n",
        "API_KEY = \"è¿™é‡Œå¡«å…¥ä½ çš„key_ä¸è¦åˆ æ‰åŒå¼•å·\"\n",
        "\n",
        "# [å¿…é¡»å¡«] ä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„\n",
        "# ä¾‹å¦‚: /content/drive/MyDrive/Lora_Training/img/20_miku\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ä½ çš„æ–‡ä»¶å¤¹è·¯å¾„\"\n",
        "\n",
        "# [å¿…é¡»å¡«] è¿™ä¸ªè§’è‰²æ˜¯è°ï¼Ÿ(ç”¨äºè¾…åŠ©AIè¯†åˆ«ç‰¹å¾)\n",
        "# ä¾‹å¦‚: Hatsune Miku\n",
        "CHARACTER_NAME = \"å¡«å†™è§’è‰²è‹±æ–‡å\"\n",
        "\n",
        "# [å¯é€‰] å‡ºè‡ªå“ªéƒ¨ä½œå“ï¼Ÿ(å¦‚æœä¸çŸ¥é“å¯ä»¥ç•™ç©º)\n",
        "# ä¾‹å¦‚: Vocaloid\n",
        "SERIES_NAME = \"å¡«å†™ä½œå“è‹±æ–‡å\"\n",
        "\n",
        "# [å¯é€‰] è§¦å‘è¯ (ä¼šè‡ªåŠ¨åŠ åœ¨æ ‡ç­¾æœ€å‰é¢)\n",
        "# é€šå¸¸å’Œè§’è‰²åä¸€è‡´ï¼Œä¾‹å¦‚: miku\n",
        "TRIGGER_WORD = \"miku\"\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. å®‰è£… zai-sdk\n",
        "print(\"ğŸ”§ æ­£åœ¨æ£€æŸ¥ç¯å¢ƒ...\")\n",
        "try:\n",
        "    from zai import ZhipuAiClient\n",
        "except ImportError:\n",
        "    print(\"â¬‡ï¸ æ­£åœ¨å®‰è£… zai-sdk...\")\n",
        "    !pip install zai-sdk -q\n",
        "    from zai import ZhipuAiClient\n",
        "    print(\"âœ… å®‰è£…å®Œæˆ\")\n",
        "\n",
        "def rename_images_sequentially(folder_path):\n",
        "    \"\"\"å°†æ–‡ä»¶å¤¹å†…çš„å›¾ç‰‡é‡å‘½åä¸º 001.ext, 002.ext ...\"\"\"\n",
        "    print(f\"ğŸ”„ æ­£åœ¨æ£€æŸ¥æ–‡ä»¶åè§„èŒƒæ€§...\")\n",
        "\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
        "    files = []\n",
        "    for ext in extensions:\n",
        "        files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
        "\n",
        "    # æŒ‰åŸæ–‡ä»¶åæ’åºï¼Œä¿è¯é¡ºåºä¸€è‡´\n",
        "    files.sort()\n",
        "\n",
        "    count = 0\n",
        "    for i, old_path in enumerate(files):\n",
        "        folder = os.path.dirname(old_path)\n",
        "        ext = os.path.splitext(old_path)[1]\n",
        "\n",
        "        # ç›®æ ‡æ–°åå­—: 001.png, 002.jpg ...\n",
        "        new_name = f\"{i+1:03d}{ext}\"\n",
        "        new_path = os.path.join(folder, new_name)\n",
        "\n",
        "        # å¦‚æœåå­—å·²ç»æ˜¯ 001.png è¿™ç§æ ¼å¼ï¼Œå°±ä¸åŠ¨å®ƒ\n",
        "        if old_path == new_path:\n",
        "            continue\n",
        "\n",
        "        # é˜²æ­¢é‡åå†²çªï¼Œå…ˆé‡å‘½åä¸ºä¸€ä¸ªä¸´æ—¶åå­—\n",
        "        temp_path = os.path.join(folder, f\"temp_{int(time.time())}_{i}{ext}\")\n",
        "        os.rename(old_path, temp_path)\n",
        "        # å†é‡å‘½åä¸ºç›®æ ‡åå­—\n",
        "        os.rename(temp_path, new_path)\n",
        "        count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        print(f\"âœ… å·²å°† {count} å¼ å›¾ç‰‡é‡å‘½åä¸º 001, 002... æ ¼å¼\")\n",
        "    else:\n",
        "        print(f\"âœ… æ–‡ä»¶åå·²ç¬¦åˆè§„èŒƒï¼Œæ— éœ€é‡å‘½å\")\n",
        "\n",
        "def generate_tags(client, image_path, char_name, series_name):\n",
        "    \"\"\"å‘é€ç»™ GLM-4.6v è·å–æ ‡ç­¾\"\"\"\n",
        "\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        img_base = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    # æ„å»ºæ›´æœ‰é’ˆå¯¹æ€§çš„ Prompt\n",
        "    series_info = f\"from the series '{series_name}'\" if series_name else \"\"\n",
        "\n",
        "    prompt_text = f\"\"\"\n",
        "    This image contains the character \"{char_name}\" {series_info}.\n",
        "    I need to train a LoRA model to mimic this character's style and appearance.\n",
        "\n",
        "    Please describe this image using Stable Diffusion tag format.\n",
        "    Rules:\n",
        "    1. Output strictly comma-separated English keywords.\n",
        "    2. IMPORTANT: Describe specific traits of \"{char_name}\" (e.g., specific hair ornaments, eye shape, outfit details).\n",
        "    3. Describe the pose, background, and framing.\n",
        "    4. NO sentences. NO \"The image shows...\". Just tags.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"glm-4.6v\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": img_base}},\n",
        "                        {\"type\": \"text\", \"text\": prompt_text}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"   [Error] APIè°ƒç”¨å¤±è´¥: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    if \"è¿™é‡Œå¡«å…¥\" in API_KEY:\n",
        "        print(\"âŒ é”™è¯¯ï¼šè¯·å…ˆåœ¨ä»£ç æœ€ä¸Šæ–¹å¡«å…¥ä½ çš„ API Keyï¼\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(IMAGE_FOLDER_PATH):\n",
        "        print(f\"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è·¯å¾„ -> {IMAGE_FOLDER_PATH}\")\n",
        "        return\n",
        "\n",
        "    # 1. å…ˆæ‰§è¡Œé‡å‘½å\n",
        "    rename_images_sequentially(IMAGE_FOLDER_PATH)\n",
        "\n",
        "    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
        "    client = ZhipuAiClient(api_key=API_KEY)\n",
        "\n",
        "    # 3. é‡æ–°æ‰«æï¼ˆå› ä¸ºæ–‡ä»¶åå˜äº†ï¼‰\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
        "    image_files = []\n",
        "    for ext in extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext)))\n",
        "    image_files.sort()\n",
        "\n",
        "    total = len(image_files)\n",
        "    print(f\"\\nğŸš€ å¼€å§‹æ™ºèƒ½æ‰“æ ‡ (è§’è‰²: {CHARACTER_NAME})...\")\n",
        "\n",
        "    for i, img_path in enumerate(image_files):\n",
        "        filename = os.path.basename(img_path)\n",
        "        txt_path = os.path.splitext(img_path)[0] + \".txt\"\n",
        "\n",
        "        print(f\"[{i+1}/{total}] å¤„ç†: {filename} ...\", end=\"\", flush=True)\n",
        "\n",
        "        # è·³è¿‡å·²å­˜åœ¨çš„txt\n",
        "        if os.path.exists(txt_path):\n",
        "            print(\" â­ï¸ è·³è¿‡\")\n",
        "            continue\n",
        "\n",
        "        tags = generate_tags(client, img_path, CHARACTER_NAME, SERIES_NAME)\n",
        "\n",
        "        if tags:\n",
        "            # æ¸…æ´—æ•°æ®\n",
        "            tags = tags.replace(\"Tags:\", \"\").replace(\"Keywords:\", \"\").strip()\n",
        "            if tags.endswith(\".\"): tags = tags[:-1]\n",
        "\n",
        "            # ç»„åˆæœ€ç»ˆå†…å®¹: è§¦å‘è¯ + è¯†åˆ«åˆ°çš„Tag\n",
        "            final_content = tags\n",
        "            if TRIGGER_WORD:\n",
        "                final_content = f\"{TRIGGER_WORD}, {tags}\"\n",
        "\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(final_content)\n",
        "            print(\" âœ…\")\n",
        "            time.sleep(0.5)\n",
        "        else:\n",
        "            print(\" âŒ\")\n",
        "\n",
        "    print(\"\\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼æ–‡ä»¶å·²é‡å‘½åå¹¶ç”Ÿæˆæ ‡ç­¾ã€‚\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PAgczKW3KW1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ğŸ˜¶â€ğŸŒ«ï¸ ç»ˆæç‰ˆï¼šå³ä¸‹è§’å±€éƒ¨æ¨¡ç³Š (æ¶ˆé™¤æ°´å°ç—•è¿¹)\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "# ================= é…ç½®åŒºåŸŸ =================\n",
        "# [å¿…é¡»å¡«] ä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ä½ çš„æ–‡ä»¶å¤¹è·¯å¾„\"\n",
        "\n",
        "# [é‡è¦] æ¨¡ç³ŠåŒºåŸŸçš„å¤§å° (åƒç´ )\n",
        "# åªè¦èƒ½è¦†ç›–ä½æ°´å°å³å¯\n",
        "BLUR_WIDTH = 220\n",
        "BLUR_HEIGHT = 80\n",
        "\n",
        "# æ¨¡ç³Šå¼ºåº¦ (åŠå¾„)\n",
        "# 15-20 å·¦å³é€šå¸¸è¶³ä»¥æŠŠå­—å½»åº•ç³Šæˆä¸€å›¢é¢œè‰²\n",
        "BLUR_RADIUS = 20\n",
        "# ===========================================\n",
        "\n",
        "def blur_watermark(img_path):\n",
        "    \"\"\"åœ¨å›¾ç‰‡å³ä¸‹è§’è¿›è¡Œé«˜æ–¯æ¨¡ç³Š\"\"\"\n",
        "    try:\n",
        "        # æ‰“å¼€å›¾ç‰‡\n",
        "        img = Image.open(img_path).convert('RGBA')\n",
        "        w, h = img.size\n",
        "\n",
        "        # æ£€æŸ¥å›¾ç‰‡å¤§å°\n",
        "        if h <= BLUR_HEIGHT or w <= BLUR_WIDTH:\n",
        "            print(f\" âš ï¸ å›¾ç‰‡å¤ªå°ï¼Œè·³è¿‡: {os.path.basename(img_path)}\")\n",
        "            return False\n",
        "\n",
        "        # 1. åˆ‡å‡ºå³ä¸‹è§’é‚£ä¸€å°å—\n",
        "        box = (w - BLUR_WIDTH, h - BLUR_HEIGHT, w, h)\n",
        "        region = img.crop(box)\n",
        "\n",
        "        # 2. å¯¹è¿™ä¸€å°å—è¿›è¡Œå¼ºåŠ›æ¨¡ç³Š\n",
        "        # é‡å¤æ¨¡ç³Šå‡ æ¬¡ç¡®ä¿æ–‡å­—å½»åº•æ¶ˆå¤±\n",
        "        for _ in range(3):\n",
        "            region = region.filter(ImageFilter.GaussianBlur(radius=BLUR_RADIUS))\n",
        "\n",
        "        # 3. è´´å›å»\n",
        "        img.paste(region, box)\n",
        "\n",
        "        # 4. ä¿å­˜\n",
        "        if img_path.lower().endswith(('.jpg', '.jpeg')):\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        img.save(img_path, quality=100, subsampling=0)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\" âŒ å¤„ç†å‡ºé”™: {os.path.basename(img_path)} - {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IMAGE_FOLDER_PATH):\n",
        "        print(f\"âŒ æ‰¾ä¸åˆ°è·¯å¾„: {IMAGE_FOLDER_PATH}\")\n",
        "        return\n",
        "\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
        "    image_files = []\n",
        "    for ext in extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext)))\n",
        "        image_files.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext.upper())))\n",
        "\n",
        "    image_files = sorted(list(set(image_files)))\n",
        "    total = len(image_files)\n",
        "\n",
        "    if total == 0:\n",
        "        print(\"ğŸ“‚ æ²¡æ‰¾åˆ°å›¾ç‰‡ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(f\"ğŸ“‚ å‡†å¤‡æ¨¡ç³Šå¤„ç† {total} å¼ å›¾ç‰‡...\")\n",
        "    print(f\"ğŸ˜¶â€ğŸŒ«ï¸ æ¨¡ç³ŠåŒºåŸŸ: å³ä¸‹è§’ {BLUR_WIDTH}x{BLUR_HEIGHT}\")\n",
        "\n",
        "    success_count = 0\n",
        "    for i, img_path in enumerate(image_files):\n",
        "        filename = os.path.basename(img_path)\n",
        "        print(f\"[{i+1}/{total}] å¤„ç†: {filename}\", end=\"\", flush=True)\n",
        "\n",
        "        if blur_watermark(img_path):\n",
        "            print(\" -> âœ… å·²æ¨¡ç³Š\")\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(\"\")\n",
        "\n",
        "    print(f\"\\nğŸ‰ å…¨éƒ¨å®Œæˆï¼æ°´å°å·²å˜æˆä¸€å›¢è¿™ç§é¢œè‰²çš„é›¾æ°”ï¼ŒAI å¾ˆéš¾å­¦åˆ°å½¢çŠ¶ã€‚\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "7kMfrbXWKOrN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}