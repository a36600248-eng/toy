{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a36600248-eng/toy/blob/main/kohya_ss_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrgcDwZxgDOe"
      },
      "outputs": [],
      "source": [
        "#@title Train with Kohya's Stable Diffusion Trainers\n",
        "%cd /content\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install dadaptation==3.1 diffusers[torch]==0.17.1 easygui==0.98.3 einops==0.6.0 fairscale==0.4.13 ftfy==6.1.1 gradio==3.36.1 huggingface-hub==0.14.1\n",
        "!pip install lion-pytorch==0.0.6 lycoris_lora==1.8.0.dev6 open-clip-torch==2.20.0 prodigyopt==1.0 pytorch-lightning==1.9.0 safetensors==0.3.1 timm==0.6.12\n",
        "!pip install tk==0.1.0 transformers==4.30.2 voluptuous==0.13.1 wandb==0.15.0 xformers==0.0.20 omegaconf\n",
        "\n",
        "%cd /content\n",
        "!git clone -b 0.41.0 https://github.com/TimDettmers/bitsandbytes\n",
        "%cd /content/bitsandbytes\n",
        "!CUDA_VERSION=118 make cuda11x\n",
        "!python setup.py install\n",
        "\n",
        "%cd /content\n",
        "!git clone -b v1.0 https://github.com/camenduru/kohya_ss\n",
        "%cd /content/kohya_ss\n",
        "\n",
        "!python kohya_gui.py --share --headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8qrgrv_gLNRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ä¸€é”®é¢„å¤„ç†ï¼šè‡ªåŠ¨é‡å‘½å + æ™ºèƒ½æ‰“æ ‡ (GLM-4.6v)\n",
        "# @markdown ### 1. æ ¸å¿ƒé…ç½®\n",
        "import os\n",
        "import glob\n",
        "import base64\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# [å¿…é¡»å¡«] ä½ çš„æ™ºè°±AI API Key\n",
        "API_KEY = \"è¿™é‡Œå¡«å…¥ä½ çš„key_ä¸è¦åˆ æ‰åŒå¼•å·\"\n",
        "\n",
        "# [å¿…é¡»å¡«] ä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„\n",
        "# ä¾‹å¦‚: /content/drive/MyDrive/Lora_Training/img/20_miku\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ä½ çš„æ–‡ä»¶å¤¹è·¯å¾„\"\n",
        "\n",
        "# [å¿…é¡»å¡«] è¿™ä¸ªè§’è‰²æ˜¯è°ï¼Ÿ(ç”¨äºè¾…åŠ©AIè¯†åˆ«ç‰¹å¾)\n",
        "# ä¾‹å¦‚: Hatsune Miku\n",
        "CHARACTER_NAME = \"å¡«å†™è§’è‰²è‹±æ–‡å\"\n",
        "\n",
        "# [å¯é€‰] å‡ºè‡ªå“ªéƒ¨ä½œå“ï¼Ÿ(å¦‚æœä¸çŸ¥é“å¯ä»¥ç•™ç©º)\n",
        "# ä¾‹å¦‚: Vocaloid\n",
        "SERIES_NAME = \"å¡«å†™ä½œå“è‹±æ–‡å\"\n",
        "\n",
        "# [å¯é€‰] è§¦å‘è¯ (ä¼šè‡ªåŠ¨åŠ åœ¨æ ‡ç­¾æœ€å‰é¢)\n",
        "# é€šå¸¸å’Œè§’è‰²åä¸€è‡´ï¼Œä¾‹å¦‚: miku\n",
        "TRIGGER_WORD = \"miku\"\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. å®‰è£… zai-sdk\n",
        "print(\"ğŸ”§ æ­£åœ¨æ£€æŸ¥ç¯å¢ƒ...\")\n",
        "try:\n",
        "    from zai import ZhipuAiClient\n",
        "except ImportError:\n",
        "    print(\"â¬‡ï¸ æ­£åœ¨å®‰è£… zai-sdk...\")\n",
        "    !pip install zai-sdk -q\n",
        "    from zai import ZhipuAiClient\n",
        "    print(\"âœ… å®‰è£…å®Œæˆ\")\n",
        "\n",
        "def rename_images_sequentially(folder_path):\n",
        "    \"\"\"å°†æ–‡ä»¶å¤¹å†…çš„å›¾ç‰‡é‡å‘½åä¸º 001.ext, 002.ext ...\"\"\"\n",
        "    print(f\"ğŸ”„ æ­£åœ¨æ£€æŸ¥æ–‡ä»¶åè§„èŒƒæ€§...\")\n",
        "\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
        "    files = []\n",
        "    for ext in extensions:\n",
        "        files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
        "\n",
        "    # æŒ‰åŸæ–‡ä»¶åæ’åºï¼Œä¿è¯é¡ºåºä¸€è‡´\n",
        "    files.sort()\n",
        "\n",
        "    count = 0\n",
        "    for i, old_path in enumerate(files):\n",
        "        folder = os.path.dirname(old_path)\n",
        "        ext = os.path.splitext(old_path)[1]\n",
        "\n",
        "        # ç›®æ ‡æ–°åå­—: 001.png, 002.jpg ...\n",
        "        new_name = f\"{i+1:03d}{ext}\"\n",
        "        new_path = os.path.join(folder, new_name)\n",
        "\n",
        "        # å¦‚æœåå­—å·²ç»æ˜¯ 001.png è¿™ç§æ ¼å¼ï¼Œå°±ä¸åŠ¨å®ƒ\n",
        "        if old_path == new_path:\n",
        "            continue\n",
        "\n",
        "        # é˜²æ­¢é‡åå†²çªï¼Œå…ˆé‡å‘½åä¸ºä¸€ä¸ªä¸´æ—¶åå­—\n",
        "        temp_path = os.path.join(folder, f\"temp_{int(time.time())}_{i}{ext}\")\n",
        "        os.rename(old_path, temp_path)\n",
        "        # å†é‡å‘½åä¸ºç›®æ ‡åå­—\n",
        "        os.rename(temp_path, new_path)\n",
        "        count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        print(f\"âœ… å·²å°† {count} å¼ å›¾ç‰‡é‡å‘½åä¸º 001, 002... æ ¼å¼\")\n",
        "    else:\n",
        "        print(f\"âœ… æ–‡ä»¶åå·²ç¬¦åˆè§„èŒƒï¼Œæ— éœ€é‡å‘½å\")\n",
        "\n",
        "def generate_tags(client, image_path, char_name, series_name):\n",
        "    \"\"\"å‘é€ç»™ GLM-4.6v è·å–æ ‡ç­¾\"\"\"\n",
        "\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        img_base = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    # æ„å»ºæ›´æœ‰é’ˆå¯¹æ€§çš„ Prompt\n",
        "    series_info = f\"from the series '{series_name}'\" if series_name else \"\"\n",
        "\n",
        "    prompt_text = f\"\"\"\n",
        "    This image contains the character \"{char_name}\" {series_info}.\n",
        "    I need to train a LoRA model to mimic this character's style and appearance.\n",
        "\n",
        "    Please describe this image using Stable Diffusion tag format.\n",
        "    Rules:\n",
        "    1. Output strictly comma-separated English keywords.\n",
        "    2. IMPORTANT: Describe specific traits of \"{char_name}\" (e.g., specific hair ornaments, eye shape, outfit details).\n",
        "    3. Describe the pose, background, and framing.\n",
        "    4. NO sentences. NO \"The image shows...\". Just tags.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"glm-4.6v\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": img_base}},\n",
        "                        {\"type\": \"text\", \"text\": prompt_text}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"   [Error] APIè°ƒç”¨å¤±è´¥: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    if \"è¿™é‡Œå¡«å…¥\" in API_KEY:\n",
        "        print(\"âŒ é”™è¯¯ï¼šè¯·å…ˆåœ¨ä»£ç æœ€ä¸Šæ–¹å¡«å…¥ä½ çš„ API Keyï¼\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(IMAGE_FOLDER_PATH):\n",
        "        print(f\"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è·¯å¾„ -> {IMAGE_FOLDER_PATH}\")\n",
        "        return\n",
        "\n",
        "    # 1. å…ˆæ‰§è¡Œé‡å‘½å\n",
        "    rename_images_sequentially(IMAGE_FOLDER_PATH)\n",
        "\n",
        "    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
        "    client = ZhipuAiClient(api_key=API_KEY)\n",
        "\n",
        "    # 3. é‡æ–°æ‰«æï¼ˆå› ä¸ºæ–‡ä»¶åå˜äº†ï¼‰\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
        "    image_files = []\n",
        "    for ext in extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext)))\n",
        "    image_files.sort()\n",
        "\n",
        "    total = len(image_files)\n",
        "    print(f\"\\nğŸš€ å¼€å§‹æ™ºèƒ½æ‰“æ ‡ (è§’è‰²: {CHARACTER_NAME})...\")\n",
        "\n",
        "    for i, img_path in enumerate(image_files):\n",
        "        filename = os.path.basename(img_path)\n",
        "        txt_path = os.path.splitext(img_path)[0] + \".txt\"\n",
        "\n",
        "        print(f\"[{i+1}/{total}] å¤„ç†: {filename} ...\", end=\"\", flush=True)\n",
        "\n",
        "        # è·³è¿‡å·²å­˜åœ¨çš„txt\n",
        "        if os.path.exists(txt_path):\n",
        "            print(\" â­ï¸ è·³è¿‡\")\n",
        "            continue\n",
        "\n",
        "        tags = generate_tags(client, img_path, CHARACTER_NAME, SERIES_NAME)\n",
        "\n",
        "        if tags:\n",
        "            # æ¸…æ´—æ•°æ®\n",
        "            tags = tags.replace(\"Tags:\", \"\").replace(\"Keywords:\", \"\").strip()\n",
        "            if tags.endswith(\".\"): tags = tags[:-1]\n",
        "\n",
        "            # ç»„åˆæœ€ç»ˆå†…å®¹: è§¦å‘è¯ + è¯†åˆ«åˆ°çš„Tag\n",
        "            final_content = tags\n",
        "            if TRIGGER_WORD:\n",
        "                final_content = f\"{TRIGGER_WORD}, {tags}\"\n",
        "\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(final_content)\n",
        "            print(\" âœ…\")\n",
        "            time.sleep(0.5)\n",
        "        else:\n",
        "            print(\" âŒ\")\n",
        "\n",
        "    print(\"\\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼æ–‡ä»¶å·²é‡å‘½åå¹¶ç”Ÿæˆæ ‡ç­¾ã€‚\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PAgczKW3KW1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ğŸ˜¶â€ğŸŒ«ï¸ ç»ˆæç‰ˆï¼šå³ä¸‹è§’å±€éƒ¨æ¨¡ç³Š (æ¶ˆé™¤æ°´å°ç—•è¿¹)\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "# ================= é…ç½®åŒºåŸŸ =================\n",
        "# [å¿…é¡»å¡«] ä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ä½ çš„æ–‡ä»¶å¤¹è·¯å¾„\"\n",
        "\n",
        "# [é‡è¦] æ¨¡ç³ŠåŒºåŸŸçš„å¤§å° (åƒç´ )\n",
        "# åªè¦èƒ½è¦†ç›–ä½æ°´å°å³å¯\n",
        "BLUR_WIDTH = 220\n",
        "BLUR_HEIGHT = 80\n",
        "\n",
        "# æ¨¡ç³Šå¼ºåº¦ (åŠå¾„)\n",
        "# 15-20 å·¦å³é€šå¸¸è¶³ä»¥æŠŠå­—å½»åº•ç³Šæˆä¸€å›¢é¢œè‰²\n",
        "BLUR_RADIUS = 20\n",
        "# ===========================================\n",
        "\n",
        "def blur_watermark(img_path):\n",
        "    \"\"\"åœ¨å›¾ç‰‡å³ä¸‹è§’è¿›è¡Œé«˜æ–¯æ¨¡ç³Š\"\"\"\n",
        "    try:\n",
        "        # æ‰“å¼€å›¾ç‰‡\n",
        "        img = Image.open(img_path).convert('RGBA')\n",
        "        w, h = img.size\n",
        "\n",
        "        # æ£€æŸ¥å›¾ç‰‡å¤§å°\n",
        "        if h <= BLUR_HEIGHT or w <= BLUR_WIDTH:\n",
        "            print(f\" âš ï¸ å›¾ç‰‡å¤ªå°ï¼Œè·³è¿‡: {os.path.basename(img_path)}\")\n",
        "            return False\n",
        "\n",
        "        # 1. åˆ‡å‡ºå³ä¸‹è§’é‚£ä¸€å°å—\n",
        "        box = (w - BLUR_WIDTH, h - BLUR_HEIGHT, w, h)\n",
        "        region = img.crop(box)\n",
        "\n",
        "        # 2. å¯¹è¿™ä¸€å°å—è¿›è¡Œå¼ºåŠ›æ¨¡ç³Š\n",
        "        # é‡å¤æ¨¡ç³Šå‡ æ¬¡ç¡®ä¿æ–‡å­—å½»åº•æ¶ˆå¤±\n",
        "        for _ in range(3):\n",
        "            region = region.filter(ImageFilter.GaussianBlur(radius=BLUR_RADIUS))\n",
        "\n",
        "        # 3. è´´å›å»\n",
        "        img.paste(region, box)\n",
        "\n",
        "        # 4. ä¿å­˜\n",
        "        if img_path.lower().endswith(('.jpg', '.jpeg')):\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        img.save(img_path, quality=100, subsampling=0)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\" âŒ å¤„ç†å‡ºé”™: {os.path.basename(img_path)} - {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IMAGE_FOLDER_PATH):\n",
        "        print(f\"âŒ æ‰¾ä¸åˆ°è·¯å¾„: {IMAGE_FOLDER_PATH}\")\n",
        "        return\n",
        "\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
        "    image_files = []\n",
        "    for ext in extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext)))\n",
        "        image_files.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext.upper())))\n",
        "\n",
        "    image_files = sorted(list(set(image_files)))\n",
        "    total = len(image_files)\n",
        "\n",
        "    if total == 0:\n",
        "        print(\"ğŸ“‚ æ²¡æ‰¾åˆ°å›¾ç‰‡ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(f\"ğŸ“‚ å‡†å¤‡æ¨¡ç³Šå¤„ç† {total} å¼ å›¾ç‰‡...\")\n",
        "    print(f\"ğŸ˜¶â€ğŸŒ«ï¸ æ¨¡ç³ŠåŒºåŸŸ: å³ä¸‹è§’ {BLUR_WIDTH}x{BLUR_HEIGHT}\")\n",
        "\n",
        "    success_count = 0\n",
        "    for i, img_path in enumerate(image_files):\n",
        "        filename = os.path.basename(img_path)\n",
        "        print(f\"[{i+1}/{total}] å¤„ç†: {filename}\", end=\"\", flush=True)\n",
        "\n",
        "        if blur_watermark(img_path):\n",
        "            print(\" -> âœ… å·²æ¨¡ç³Š\")\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(\"\")\n",
        "\n",
        "    print(f\"\\nğŸ‰ å…¨éƒ¨å®Œæˆï¼æ°´å°å·²å˜æˆä¸€å›¢è¿™ç§é¢œè‰²çš„é›¾æ°”ï¼ŒAI å¾ˆéš¾å­¦åˆ°å½¢çŠ¶ã€‚\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "7kMfrbXWKOrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXisrAqUKNUe"
      },
      "outputs": [],
      "source": [
        "#@title Convert Safetensors to Diffusers\n",
        "from_safetensors_url = '' #@param {type:\"string\"}\n",
        "!wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.17.1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "!wget {from_safetensors_url} -O /content/model.safetensors\n",
        "!python3 convert_original_stable_diffusion_to_diffusers.py --half --from_safetensors --checkpoint_path model.safetensors --dump_path /content/model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBmD-oeWKNUe"
      },
      "outputs": [],
      "source": [
        "#@title Push to HF.co\n",
        "\n",
        "import os\n",
        "from huggingface_hub import create_repo, upload_folder\n",
        "\n",
        "hf_token = 'HF_WRITE_TOKEN' #@param {type:\"string\"}\n",
        "repo_id = 'username/reponame' #@param {type:\"string\"}\n",
        "commit_message = '\\u2764' #@param {type:\"string\"}\n",
        "create_repo(repo_id, private=True, token=hf_token)\n",
        "model_path = '/content/train/model' #@param {type:\"string\"}\n",
        "upload_folder(folder_path=f'{model_path}', path_in_repo='', repo_id=repo_id, commit_message=commit_message, token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnLivFVMKNUe"
      },
      "outputs": [],
      "source": [
        "#@title Push to DagsHub.com\n",
        "\n",
        "!pip -q install dagshub\n",
        "from dagshub.upload import Repo, create_repo\n",
        "\n",
        "repo_id = 'reponame' #@param {type:\"string\"}\n",
        "org_name = 'orgname' #@param {type:\"string\"}\n",
        "commit_message = '\\u2764' #@param {type:\"string\"}\n",
        "create_repo(f\"{repo_id}\", org_name=f\"{org_name}\")\n",
        "repo = Repo(f\"{org_name}\", f\"{repo_id}\")\n",
        "model_path = '/content/train/model' #@param {type:\"string\"}\n",
        "repo.upload(\"/content/models\", remote_path=\"data\", commit_message=f\"{commit_message}\", force=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}